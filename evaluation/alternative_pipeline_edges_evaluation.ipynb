{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ce31844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from matplotlib.patches import Rectangle\n",
    "from gingerit.gingerit import GingerIt\n",
    "from rapidfuzz.distance import Levenshtein\n",
    "\n",
    "from transformers import AutoImageProcessor, AutoModelForObjectDetection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee135bb8",
   "metadata": {},
   "source": [
    "### One function for each step in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb3d1da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ocr_data(json_file):\n",
    "    with open(json_file) as fp:\n",
    "        data = json.loads(fp.read())\n",
    "    \n",
    "    nodes = []\n",
    "\n",
    "    for b in data['Blocks']:\n",
    "        if b['BlockType'] == 'LINE' and (len(b['Text']) > 2):\n",
    "            node = {'text': b['Text'], \n",
    "                    'left': b['Geometry']['BoundingBox']['Left'], \n",
    "                    'top': b['Geometry']['BoundingBox']['Top'],\n",
    "                    'right': b['Geometry']['BoundingBox']['Left'] + b['Geometry']['BoundingBox']['Width'],\n",
    "                    'bottom': b['Geometry']['BoundingBox']['Top'] + b['Geometry']['BoundingBox']['Height']}\n",
    "\n",
    "            nodes.append(node)\n",
    "    \n",
    "    return pd.DataFrame(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cf03d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_image(filename):\n",
    "    \n",
    "    img = cv2.imread(filename)\n",
    "    \n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aec08276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_image(image):\n",
    "    \n",
    "    img = image.copy()\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    mean_tone_value = np.mean(gray)\n",
    "    \n",
    "    #print(mean_tone_value)\n",
    "    \n",
    "    if mean_tone_value < 128:\n",
    "        \n",
    "        gray = 255 - gray\n",
    "        mean_tone_value = np.mean(gray)\n",
    "    \n",
    "    threshold_value = int(mean_tone_value * 0.8)\n",
    "    \n",
    "    _, threshold = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    threshold = 1 - (threshold / 255.)\n",
    "    \n",
    "    return threshold\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad2c2783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_bounding_boxes_in_pixels(df, img):\n",
    "    \n",
    "    img_height = img.shape[0]\n",
    "    img_width = img.shape[1]\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "         \n",
    "        df.at[i, 'left']   = int(round(row['left'] * img_width))\n",
    "        df.at[i, 'right']  = int(round(row['right'] * img_width))\n",
    "        df.at[i, 'top']    = int(round(row['top'] * img_height))\n",
    "        df.at[i, 'bottom'] = int(round(row['bottom'] * img_height))\n",
    "        \n",
    "    df['left']   = df['left'].astype(int)\n",
    "    df['right']  = df['right'].astype(int)\n",
    "    df['top']    = df['top'].astype(int)\n",
    "    df['bottom'] = df['bottom'].astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86bb7df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_font_size(df):\n",
    "    \n",
    "    df['font_size'] = df.bottom - df.top\n",
    "    \n",
    "    df['font_size'] = (df['font_size'] - df['font_size'].mean()) / (df['font_size'].std() + 1e-6)\n",
    "    \n",
    "    df['font_size'] = (df['font_size'].apply(lambda x: round(x)) + 10).astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2135a370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def substract_bounding_boxes(df, img, erotion_percent = 0):\n",
    "    \n",
    "    img_out = img.copy()\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        \n",
    "        width = row['right'] - row['left']\n",
    "        erotion_width = int(round((width * erotion_percent) / 100))\n",
    "        \n",
    "        height = row['bottom'] - row['top']\n",
    "        erotion_height = int(round((height * erotion_percent) / 100))\n",
    "        \n",
    "\n",
    "        img_out[ (row['top'] + erotion_height)  : (row['bottom'] - erotion_height), \n",
    "                 (row['left'] + erotion_width) : (row['right'] - erotion_width) ] = 0\n",
    "    \n",
    "    return img_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "282dd41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_shape_gaps5(image, ocr,\n",
    "                      dist_threshold_percent = 30, \n",
    "                      activation_lower_th = 40, \n",
    "                      activation_upper_th = 70):\n",
    "\n",
    "    img = image.copy()\n",
    "    img = (1-img) * 10\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    kernel[1,1] = 10\n",
    "\n",
    "    dst = cv2.filter2D(img,-1,kernel).astype(int)\n",
    "\n",
    "    points_thr = np.where((dst > activation_lower_th) & (dst < activation_upper_th))\n",
    "\n",
    "    points = []\n",
    "    for p_i in range(len(points_thr[0])): \n",
    "        points.append([points_thr[0][p_i], points_thr[1][p_i]])\n",
    "\n",
    "    points = np.stack(points, axis=0)\n",
    "\n",
    "    nodes_points = []\n",
    "\n",
    "    nodes_points.extend([[row.top, row.left] for i, row in ocr.iterrows()])\n",
    "    nodes_points.extend([[row.top, row.right] for i, row in ocr.iterrows()])\n",
    "    nodes_points.extend([[row.bottom, row.right] for i, row in ocr.iterrows()])\n",
    "    nodes_points.extend([[row.bottom, row.left] for i, row in ocr.iterrows()])\n",
    "\n",
    "    nodes_points   = np.array(nodes_points)\n",
    "    dist_matrix    = euclidean_distances(points)\n",
    "    max_bb_height  = (ocr.bottom - ocr.top).max()\n",
    "    dist_threshold = int((max_bb_height * dist_threshold_percent)/100)\n",
    "\n",
    "    below_th = np.where((dist_matrix < dist_threshold) & (dist_matrix > 0)) # zero is trivial distance, no need to fill any gap\n",
    "\n",
    "    img_out = image.copy()\n",
    "\n",
    "    for i in range(len(below_th[0])):\n",
    "\n",
    "        p1 = points[below_th[0][i]]\n",
    "        p2 = points[below_th[1][i]]\n",
    "\n",
    "        dist_to_nodes = euclidean_distances(np.stack([p1, p2]), nodes_points)\n",
    "        closest_node = np.argmin(dist_to_nodes) % len(ocr)\n",
    "\n",
    "        closest_node_height = ocr.loc[closest_node, 'bottom'] - ocr.loc[closest_node, 'top']\n",
    "\n",
    "        dist_threshold = int((closest_node_height * dist_threshold_percent)/100)\n",
    "\n",
    "        if np.linalg.norm(p2-p1) < dist_threshold:\n",
    "\n",
    "            cv2.line(img_out, [p1[1],p1[0]], [p2[1],p2[0]],  (1, 1, 1), thickness=1)\n",
    "    \n",
    "    return img_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d19b59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stamp_bounding_boxes_on_image(df, img, erotion_percent = 10):\n",
    "    \n",
    "    img_out = img.copy()\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        \n",
    "        width = row['right'] - row['left']\n",
    "        erotion_width = int(round((width * erotion_percent) / 100))\n",
    "        \n",
    "        height = row['bottom'] - row['top']\n",
    "        erotion_height = int(round((height * erotion_percent) / 100))\n",
    "        \n",
    "\n",
    "        img_out[ (row['top'] + erotion_height)  : (row['bottom'] - erotion_height), \n",
    "                 (row['left'] + erotion_width) : (row['right'] - erotion_width) ] = 1\n",
    "    \n",
    "    return img_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c8c3ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filled_shapes(img):\n",
    "    \n",
    "    contours, tree = cv2.findContours(cv2.convertScaleAbs(img), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    img_out = np.zeros_like(img)\n",
    "\n",
    "    for i, contour in enumerate(contours):\n",
    "        cv2.drawContours(img_out, [contour], 0, (1, 1, 1), thickness=cv2.FILLED)\n",
    "        \n",
    "    return img_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4ac9481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masks(img, max_iter=10):\n",
    "    \n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "\n",
    "    img_eroded = [img.copy()]\n",
    "    contours_iter = []\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        contours, tree = cv2.findContours(cv2.convertScaleAbs(img_eroded[-1]), \n",
    "                                          cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours_iter.append(contours)\n",
    "        img_eroded.append(cv2.erode(img_eroded[-1], kernel, iterations = 1))\n",
    "    \n",
    "    min_contours = len(contours_iter[-1])\n",
    "    min_contours_iteration = len(contours_iter)-1\n",
    "\n",
    "    for i in range(len(contours_iter)-1, -1, -1):\n",
    "        if len(contours_iter[i]) > min_contours:\n",
    "            min_contours_iteration = i+1\n",
    "            break\n",
    "            \n",
    "            \n",
    "    nodes_mask = img_eroded[min_contours_iteration]\n",
    "    \n",
    "    nodes_mask_dilated = cv2.dilate(nodes_mask, kernel, iterations=min_contours_iteration+1)\n",
    "    edges_mask = np.maximum((img_eroded[0] - nodes_mask_dilated), 0)\n",
    "\n",
    "\n",
    "    return nodes_mask, edges_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "602ebf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edges_endpoints(edges_mask, min_edge_length_percentage = 3):\n",
    "    \n",
    "    final_edges = []\n",
    "\n",
    "    contour_idswithendpoint = []\n",
    "    edge_lengths = []\n",
    "    \n",
    "    edge_thickness = []\n",
    "    \n",
    "    min_edge_length_pixels = (min_edge_length_percentage / 100) * edges_mask.shape[0]\n",
    "\n",
    "    contours, tree = cv2.findContours(cv2.convertScaleAbs(edges_mask), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour_data = []  # A list to store (contour_id, contour, endpoints) tuples\n",
    "    contour_id = 0\n",
    "\n",
    "    for contour in contours:\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        edge_lengths.append(perimeter)  \n",
    "        contours_length = len(contour)\n",
    "\n",
    "        # Avoid division by zero\n",
    "        if contours_length == 0:\n",
    "            contours_length = 1\n",
    "        area = cv2.contourArea(contour)\n",
    "        # Calculate the thickness of the contour\n",
    "        thickness = area / contours_length\n",
    "        edge_thickness.append(thickness)  \n",
    "        \n",
    "        c = max([contour], key=cv2.contourArea)\n",
    "        \n",
    "        extreme_points = []\n",
    "\n",
    "        extreme_points.append(np.array(c[c[:, :, 0].argmin()][0]))\n",
    "        extreme_points.append(np.array(c[c[:, :, 0].argmax()][0]))\n",
    "        extreme_points.append(np.array(c[c[:, :, 1].argmin()][0]))\n",
    "        extreme_points.append(np.array(c[c[:, :, 1].argmax()][0]))\n",
    "        \n",
    "        extreme_points = np.stack(extreme_points, axis=0)\n",
    "\n",
    "        contour_data.append((contour_id, contour, extreme_points))\n",
    "\n",
    "\n",
    "        dist_mat = euclidean_distances(extreme_points)\n",
    "        if np.max(dist_mat) > min_edge_length_pixels:\n",
    "\n",
    "            ext_indeces = np.unravel_index(np.argmax(dist_mat), shape=dist_mat.shape)\n",
    "\n",
    "\n",
    "            final_endpoints = [extreme_points[ext_indeces[0]], extreme_points[ext_indeces[1]]]\n",
    "\n",
    "            final_edges.append(final_endpoints)\n",
    "            # Step 2 (Continued): Record contour ID of the endpoints\n",
    "\n",
    "            contour_idswithendpoint.append(contour_id)\n",
    "        contour_id = contour_id+1\n",
    "\n",
    "\n",
    "            \n",
    "    n = len(edge_lengths)\n",
    "    ids = np.arange(n).reshape((-1, 1))\n",
    "    combined_table = np.column_stack((ids, edge_lengths, edge_thickness))    \n",
    "\n",
    "    selected_rows = combined_table[np.isin(combined_table[:, 0], contour_idswithendpoint)]\n",
    "    return np.stack(final_edges),selected_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8f1fff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes(ocr, nodes_mask, threshold_iou = 0.8):\n",
    "    \n",
    "    df = ocr.copy()\n",
    "    nodes_contours, tree = cv2.findContours(cv2.convertScaleAbs(nodes_mask), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "\n",
    "        area = (row['right'] - row['left']) * (row['bottom'] - row['top'])\n",
    "\n",
    "        max_iou = 0\n",
    "        max_iou_i_node = -1\n",
    "        \n",
    "\n",
    "        for i_node, contour in enumerate(nodes_contours):\n",
    "\n",
    "            empty_img = np.zeros_like(nodes_mask)\n",
    "\n",
    "            cv2.drawContours(empty_img, [contour], 0, (1, 1, 1), thickness=-1)\n",
    "\n",
    "            intersection = empty_img[row['top']:row['bottom'], row['left']:row['right']].sum()\n",
    "\n",
    "            iou = intersection / area\n",
    "\n",
    "            if iou > max_iou:\n",
    "                max_iou = iou\n",
    "                max_iou_i_node = i_node\n",
    "\n",
    "        if max_iou > threshold_iou:\n",
    "\n",
    "            df.at[i, 'node_id'] = max_iou_i_node\n",
    "            \n",
    "    df['text'] = df.groupby('node_id')['text'].transform(lambda x: '\\n'.join(x))\n",
    "    df.drop_duplicates('text', inplace=True)\n",
    "\n",
    "    df =df[df.node_id.notna()]\n",
    "    df.node_id = df.node_id.astype(int)\n",
    "    \n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8832eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conections(nodes_df, edges_endpoints, img, dist_threshold_percentage = 5):\n",
    "    \n",
    "    nodes_contours = []\n",
    "    nodes_ids = []\n",
    "    \n",
    "    for i, row in nodes_df.iterrows():\n",
    "        \n",
    "        img_out = np.zeros_like(img, dtype=np.uint16)\n",
    "        \n",
    "        img_out[ row.top : row.bottom, row.left : row.right ] = 1\n",
    "        \n",
    "        contour, tree = cv2.findContours(cv2.convertScaleAbs(img_out), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        assert len(contour) == 1\n",
    "        \n",
    "        nodes_contours.append(contour[0])\n",
    "        nodes_ids.append(row.node_id)\n",
    "        \n",
    "    \n",
    "    \n",
    "    edges_endpoints = edges_endpoints.astype(np.uint16)\n",
    "\n",
    "    connections = []\n",
    "\n",
    "    dist_threshold_in_pixels = int((dist_threshold_percentage / 100) * img.shape[0])\n",
    "\n",
    "    for edge in edges_endpoints:\n",
    "\n",
    "        connection = [None, None]\n",
    "\n",
    "        for i_endpoint, endpoint in enumerate(edge):\n",
    "\n",
    "            min_dist_to_node = 9e3\n",
    "            min_dist_node_n = -1\n",
    "\n",
    "            for i_node, node in enumerate(nodes_contours):\n",
    "\n",
    "                min_dist = cv2.pointPolygonTest(node, endpoint, True) * (-1)\n",
    "\n",
    "\n",
    "                if min_dist < min_dist_to_node:\n",
    "                    min_dist_to_node = min_dist\n",
    "                    min_dist_node_n = nodes_ids[i_node]\n",
    "\n",
    "            if min_dist_to_node < dist_threshold_in_pixels:\n",
    "\n",
    "                connection[i_endpoint] = min_dist_node_n\n",
    "\n",
    "        if connection[0] is not None and connection[1] is not None and connection[0] != connection[1]:\n",
    "            connections.append(connection) \n",
    "\n",
    "    df = pd.DataFrame(connections, columns=['node a', 'node b'])\n",
    "\n",
    "    froze_set = set([frozenset([row['node a'], row['node b']]) for i, row in df.iterrows()])\n",
    "\n",
    "    df = pd.DataFrame(froze_set, columns=['node a', 'node b'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dd8717d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_image_nodes_from_annotated_df(df):\n",
    "    \n",
    "    df = df[df.text.apply(lambda x: x.startswith('image') == False)]\n",
    "    \n",
    "    if 'type' in df.columns:\n",
    "        return df[df.type != 'image']\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "373059a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_close_nodes(ocr, vertical_distance_threshold_percent=25, horizontal_distance_threshold_percent=50):\n",
    "    \n",
    "    df = ocr.copy()\n",
    "    \n",
    "    while True:\n",
    "\n",
    "        to_add = []\n",
    "        to_remove = []\n",
    "\n",
    "        flag_updates_made = False\n",
    "\n",
    "        for i,row_a in df.iterrows():\n",
    "            for j,row_b in df.iterrows():\n",
    "\n",
    "                row_a_height = row_a.bottom - row_a.top\n",
    "                row_b_height = row_b.bottom - row_b.top\n",
    "\n",
    "                row_a_width = row_a.right - row_a.left\n",
    "                row_b_width = row_b.right - row_b.left\n",
    "\n",
    "                mean_height = (row_a_height + row_b_height) / 2\n",
    "                mean_width  = (row_a_width + row_b_width) / 2\n",
    "\n",
    "                vertical_distance_threshold_pixels   = (vertical_distance_threshold_percent / 100) * mean_height\n",
    "                horizontal_distance_threshold_pixels = (horizontal_distance_threshold_percent / 100) * mean_width\n",
    "\n",
    "                if (j > i and \n",
    "                    abs(row_b.top - row_a.bottom) < vertical_distance_threshold_pixels and\n",
    "                    abs(row_b.left - row_a.left) < horizontal_distance_threshold_pixels):\n",
    "                    \n",
    "                    df.at[i, 'text'] = row_a.text + ' ' + row_b.text\n",
    "                    df.at[i, 'bottom'] = row_b.bottom\n",
    "                    df.at[i, 'left'] = min(row_a.left, row_b.left)\n",
    "                    df.at[i, 'right'] = max(row_a.right, row_b.right)\n",
    "                    df.at[i, 'font_size'] = (row_a.font_size + row_b.font_size) / 2\n",
    "\n",
    "                    df = df.drop(j, axis=0)\n",
    "                    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                    flag_updates_made = True\n",
    "                   \n",
    "                    break\n",
    "\n",
    "            if flag_updates_made:\n",
    "                break\n",
    "        \n",
    "        if flag_updates_made == False:\n",
    "            break\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f071db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = GingerIt()\n",
    "\n",
    "def spellcheck2(text):\n",
    "    text = text.replace('&', 'and')\n",
    "    res = parser.parse(text)\n",
    "    output = res['result']\n",
    "    output = output.replace(' and ', ' & ')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1938fc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_nodes_with_closest_annotations(pred_df, annotated_df, dist_threshold = 0.35):\n",
    "    \n",
    "    predicted_df = pred_df.copy()\n",
    "    \n",
    "    predicted_df.insert(column='closest_ann_text', loc=1, value=None)\n",
    "    predicted_df.insert(column='closest_ann_node_id', loc=len(predicted_df.columns), value=-1)\n",
    "    predicted_df.insert(column='closest_ann_dist', loc=len(predicted_df.columns), value=1)\n",
    "    \n",
    "    for i, row_a in predicted_df.iterrows():\n",
    "        \n",
    "        min_dist = dist_threshold\n",
    "        min_dist_text = None\n",
    "        min_dist_node_id = -1\n",
    "        \n",
    "        for j, row_b in annotated_df.iterrows():\n",
    "\n",
    "            dist = Levenshtein.normalized_distance(row_a.text.lower(), row_b.text.lower())\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                min_dist_text = row_b.text\n",
    "                min_dist_node_id = row_b.node_id\n",
    "        \n",
    "        predicted_df.at[i, 'closest_ann_text']    = min_dist_text\n",
    "        predicted_df.at[i, 'closest_ann_node_id'] = min_dist_node_id\n",
    "        predicted_df.at[i, 'closest_ann_dist']    = min_dist\n",
    "    \n",
    "    predicted_df = predicted_df[predicted_df.closest_ann_dist < dist_threshold]\n",
    "    \n",
    "    return predicted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caf13db",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c991071",
   "metadata": {},
   "source": [
    "## functions to calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e2d743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes_metrics(ann_nodes, nodes_df):\n",
    "    \n",
    "    nodes_df = pair_nodes_with_closest_annotations(nodes_df.copy(), ann_nodes)\n",
    "    \n",
    "    predictions = set(nodes_df.closest_ann_text.apply(lambda x: x.lower()).tolist())\n",
    "    annotations = set(ann_nodes.text.apply(lambda x: x.lower()).tolist())\n",
    "    \n",
    "    tp = annotations & predictions\n",
    "    \n",
    "    precision = len(tp) / (len(predictions) + 1e-6)\n",
    "    recall    = len(tp) / (len(annotations) + 1e-6)\n",
    "    f1        = (2 * precision * recall) / (precision+recall + 1e-6)\n",
    "    \n",
    "    return f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07d4b255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edges_metrics(ann_nodes, nodes_df, ann_edges, connections_df):\n",
    "    \n",
    "    a = pd.merge(ann_edges, ann_nodes,  how='left', left_on='node_a', right_on='node_id')\n",
    "    b = pd.merge(a, ann_nodes,  how='left', left_on='node_b', right_on='node_id')\n",
    "    c = b[['text_x', 'text_y']].dropna()\n",
    "    annotations = set([frozenset([row['text_x'].lower(), row['text_y'].lower()]) for i, row in c.iterrows()])\n",
    "\n",
    "\n",
    "    nodes_df = pair_nodes_with_closest_annotations(nodes_df, ann_nodes)\n",
    "    a = pd.merge(connections_df, nodes_df,  how='left', left_on='node a', right_on='node_id')\n",
    "    b = pd.merge(a, nodes_df,  how='left', left_on='node b', right_on='node_id')\n",
    "    c = b[['closest_ann_text_x', 'closest_ann_text_y']].fillna('None')\n",
    "    predictions = set([frozenset([row['closest_ann_text_x'].lower(), row['closest_ann_text_y'].lower()]) for i, row in c.iterrows()])\n",
    "\n",
    "    tp = annotations & predictions\n",
    "\n",
    "    precision = len(tp) / (len(predictions) + 1e-6)\n",
    "    recall    = len(tp) / (len(annotations) + 1e-6)\n",
    "    f1        = (2 * precision * recall) / (precision+recall + 1e-6)\n",
    "\n",
    "    return f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c0de5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_direction_metrics(ann_nodes, nodes_df, ann_edges, connections_df):\n",
    "    \n",
    "    a = pd.merge(ann_edges, ann_nodes,  how='left', left_on='node_a', right_on='node_id')\n",
    "    b = pd.merge(a, ann_nodes,  how='left', left_on='node_b', right_on='node_id')\n",
    "    \n",
    "    if b['destination_node'].isna().all():\n",
    "        b['destination_node'] = -1\n",
    "        \n",
    "    c = pd.merge(b, ann_nodes,  how='left', left_on='destination_node', right_on='node_id')\n",
    "    annotations = c[['text_x', 'text_y',  'text']]\n",
    "    annotations.columns = ['node a', 'node b', 'destination node']\n",
    "\n",
    "    annotations.loc[(ann_edges.direction.apply(str.lower) != 'directed') & \n",
    "              (ann_edges.direction.apply(str.lower) != 'direction') & \n",
    "              (ann_edges.direction.apply(str.lower) != 'direct'), 'destination node'] = -1\n",
    "    \n",
    "\n",
    "\n",
    "    nodes_df = pair_nodes_with_closest_annotations(nodes_df.copy(), ann_nodes)\n",
    "\n",
    "    a = pd.merge(connections_df, nodes_df,  how='left', left_on='node a', right_on='node_id')\n",
    "    b = pd.merge(a, nodes_df,  how='left', left_on='node b', right_on='node_id')\n",
    "    \n",
    "    if b['destination node'].isna().all():\n",
    "        b['destination node'] = -1\n",
    "        \n",
    "    c = pd.merge(b, nodes_df,  how='left', left_on='destination node', right_on='node_id')\n",
    "    predictions = c[['closest_ann_text_x', 'closest_ann_text_y', 'closest_ann_text']].fillna('None')\n",
    "    predictions.columns = ['node a', 'node b', 'destination node']\n",
    "    predictions.loc[predictions['destination node']=='None', 'destination node'] = -1\n",
    "    \n",
    "      \n",
    "\n",
    "    tp = 0\n",
    "    for i, row in annotations.iterrows():\n",
    "        a = predictions[(predictions['node a'] == row['node a']) & \n",
    "                    (predictions['node b'] == row['node b']) &\n",
    "                    (predictions['destination node'] == row['destination node'])]\n",
    "\n",
    "        b = predictions[(predictions['node a'] == row['node b']) & \n",
    "                    (predictions['node b'] == row['node a']) &\n",
    "                    (predictions['destination node'] == row['destination node'])]\n",
    "\n",
    "        if len(a) + len(b) > 0:\n",
    "            tp += 1\n",
    "\n",
    "    precision = tp / (len(predictions) + 1e-6)\n",
    "    recall    = tp / (len(annotations) + 1e-6)\n",
    "    f1        = (2 * precision * recall) / (precision+recall + 1e-6)\n",
    "\n",
    "    return f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "606ed7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(nodes_f1, nodes_pr, nodes_re, \n",
    "                 edges_f1, edges_pr, edges_re,\n",
    "                 directions_f1, directions_pr, directions_re):\n",
    "    \n",
    "    sns.set_theme()\n",
    "\n",
    "    fig, ax = plt.subplots(1,3, figsize=(12,4))\n",
    "\n",
    "    ax[0].plot(range(1,len(nodes_f1)+1), nodes_f1, label='F1')\n",
    "    ax[0].plot(range(1,len(nodes_pr)+1), nodes_pr, label='Precision')\n",
    "    ax[0].plot(range(1,len(nodes_re)+1), nodes_re, label='Recall')\n",
    "    ax[0].set_ylim(0,1)\n",
    "    ax[0].set_title('Node retrieval')\n",
    "    ax[0].legend()\n",
    "\n",
    "    ax[1].plot(range(1,len(edges_f1)+1), edges_f1, label='F1')\n",
    "    ax[1].plot(range(1,len(edges_pr)+1), edges_pr, label='Precision')\n",
    "    ax[1].plot(range(1,len(edges_re)+1), edges_re, label='Recall')\n",
    "    ax[1].set_ylim(0,1)\n",
    "    ax[1].set_title('Edge retrieval')\n",
    "    ax[1].legend()\n",
    "    \n",
    "    ax[2].plot(range(1,len(directions_f1)+1), directions_f1, label='F1')\n",
    "    ax[2].plot(range(1,len(directions_pr)+1), directions_pr, label='Precision')\n",
    "    ax[2].plot(range(1,len(directions_re)+1), directions_re, label='Recall')\n",
    "    ax[2].set_ylim(0,1)\n",
    "    ax[2].set_title('Directionality retrieval')\n",
    "    ax[2].legend()\n",
    "    \n",
    "    print(f'Mean F1-score for node retrieval: {np.mean(nodes_f1)}')\n",
    "    print(f'Mean F1-score for edge retrieval: {np.mean(edges_f1)}')\n",
    "    print(f'Mean F1-score for directionality retrieval: {np.mean(directions_f1)}')\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f09f31",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e13e102",
   "metadata": {},
   "source": [
    "## get all annotated examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5204da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of annotated examples: 21\n"
     ]
    }
   ],
   "source": [
    "main_folder = '../annotated_examples'\n",
    "\n",
    "ann_examples = sorted(os.listdir(main_folder))\n",
    "\n",
    "n_examples = len(ann_examples)\n",
    "\n",
    "print(f'number of annotated examples: {n_examples}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d1d93ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_exclude_to_time_complexity = ['Hipshot for inflation',\n",
    "                                 'IMG_0300-1664016398.2217-scaled',\n",
    "                                 'Mathematics Map',\n",
    "                                 'erythrocytes L1_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197aedce",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36ec5a7",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c39184",
   "metadata": {},
   "source": [
    "# adding edge direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "abc7a2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_contours_thickness(contours):\n",
    "    thickness_list = []\n",
    "\n",
    "    for contour in contours:\n",
    "        # Calculate the area of the contour\n",
    "        area = cv2.contourArea(contour)\n",
    "\n",
    "        # Calculate the length of the contour\n",
    "        length = len(contour)\n",
    "\n",
    "        # Avoid division by zero\n",
    "        if length == 0:\n",
    "            length = 1\n",
    "\n",
    "        # Calculate the thickness of the contour\n",
    "        thickness = area / length\n",
    "\n",
    "        # Add the thickness to the thickness list\n",
    "        thickness_list.append(thickness)\n",
    "\n",
    "    return thickness_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "359f6955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_arrow_detection(img_gray,dilate,erode):\n",
    "     \n",
    "    img_blur = cv2.GaussianBlur(img_gray, (5, 5), 1)\n",
    "    \n",
    "    img_canny = cv2.Canny(img_blur, 50, 50)\n",
    "    \n",
    "    kernel = np.ones((3, 3))\n",
    "    \n",
    "    img_dilate = cv2.dilate(img_canny, kernel, iterations=dilate)\n",
    "    img_erode  = cv2.erode(img_dilate, kernel, iterations=erode)\n",
    "    \n",
    "    return img_erode\n",
    "\n",
    "\n",
    "\n",
    "def find_tip(points, convex_hull):\n",
    "    \n",
    "    length = len(points)\n",
    "    \n",
    "    indices = np.setdiff1d(range(length), convex_hull)\n",
    "\n",
    "    for i in range(2):\n",
    "        \n",
    "        j = indices[i] + 2\n",
    "        if j > length - 1:\n",
    "            j = length - j\n",
    "            \n",
    "        if np.all(points[j] == points[indices[i - 1] - 2]):\n",
    "            return tuple(points[j])\n",
    "        \n",
    "def find_arrow_tail(arrow_tip, contour):\n",
    "    # Calculate the distances between the arrow tip and all points in the contour\n",
    "    distances = [np.linalg.norm(arrow_tip - point[0]) for point in contour]\n",
    "\n",
    "    # Find the index of the point with the maximum distance (farthest point)\n",
    "    farthest_point_index = np.argmax(distances)\n",
    "\n",
    "    # Get the farthest point coordinates\n",
    "    arrow_tail = tuple(contour[farthest_point_index][0])\n",
    "\n",
    "    return arrow_tail\n",
    "\n",
    "def detect_arrows(img, dilate_max=5, erode_max=5, rounding_max = 0.05, rounding_step=0.002):\n",
    "    \n",
    "    arrow_contours = []\n",
    "    \n",
    "    arrow_tips = []\n",
    "    arrow_origins = []\n",
    "    arrow_lengths = []\n",
    "    arrow_thickness = []\n",
    "    \n",
    "    dilates = list(range(0, dilate_max))\n",
    "    erotions = list(range(0, erode_max))\n",
    "    roundings = np.arange(0.001, rounding_max, rounding_step)\n",
    "\n",
    "    combinations = []\n",
    "\n",
    "    for d in dilates:\n",
    "        for e in erotions:\n",
    "            for r in roundings:\n",
    "                combinations.append({'dilate': d, 'erotion': e, 'rounding': r})\n",
    "    \n",
    "    for comb in combinations:\n",
    "        \n",
    "        contours, hierarchy = cv2.findContours(preprocess_for_arrow_detection(img, comb['dilate'], comb['erotion']), \n",
    "                                               cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "        for cnt in contours:\n",
    "            peri = cv2.arcLength(cnt, True)\n",
    "            approx = cv2.approxPolyDP(cnt, comb['rounding'] * peri, True)\n",
    "            hull = cv2.convexHull(approx, returnPoints=False)\n",
    "            sides = len(hull)\n",
    "\n",
    "            if 6 > sides > 3 and sides + 2 == len(approx):\n",
    "                \n",
    "                bol_repeated_contour = False\n",
    "                \n",
    "                for i,c in enumerate(arrow_contours):\n",
    "                    if cv2.matchShapes(c, cnt, 1, 0.0) < 1:\n",
    "                        bol_repeated_contour = True\n",
    "                        break\n",
    "                \n",
    "                if bol_repeated_contour == False:\n",
    "                    arrow_contours.append(cnt)\n",
    "                    arrow_tip = find_tip(approx[:, 0, :], hull.squeeze())\n",
    "\n",
    "                    if arrow_tip:\n",
    "                        arrow_tips.append(arrow_tip)\n",
    "                        arrow_tail = find_arrow_tail(arrow_tip, cnt)\n",
    "                        # caculate the lenth\n",
    "                        length = np.linalg.norm(np.array(arrow_tip) - np.array(arrow_tail))\n",
    "                        arrow_lengths.append(length)\n",
    "                        dist_mat = euclidean_distances(np.expand_dims(arrow_tip, axis=0), np.squeeze(cnt))\n",
    "                        \n",
    "                        \n",
    "                        area = cv2.contourArea(cnt)\n",
    "\n",
    "                        # Calculate the length of the contour\n",
    "                        contours_length = len(cnt)\n",
    "\n",
    "                        # Avoid division by zero\n",
    "                        if contours_length == 0:\n",
    "                            contours_length = 1\n",
    "\n",
    "                        # Calculate the thickness of the contour\n",
    "                        thickness = area / contours_length\n",
    "                        arrow_thickness.append(thickness)\n",
    "                        arrow_origin = np.squeeze(cnt)[np.argmax(dist_mat)]\n",
    "                        arrow_origins.append(arrow_origin)\n",
    "\n",
    "    \n",
    "    arrow_origins = np.array(arrow_origins)\n",
    "    arrow_tips    = np.array(arrow_tips)\n",
    "    arrow_lengths = np.array(arrow_lengths)\n",
    "    arrow_thickness = np.array(arrow_thickness)\n",
    "        \n",
    "    return arrow_origins, arrow_tips,arrow_lengths,arrow_thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51862c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edges_endpoints_directionality(edges_endpoints, tips, origins, dist_threshold=50):\n",
    "\n",
    "    tips_origins = np.concatenate([tips, origins], axis=1)\n",
    "    origins_tips = np.concatenate([origins, tips], axis=1)\n",
    "\n",
    "    dist_mat_tips_origins = euclidean_distances(edges_endpoints.reshape((edges_endpoints.shape[0], 4)), tips_origins)\n",
    "    dist_mat_origins_tips = euclidean_distances(edges_endpoints.reshape((edges_endpoints.shape[0], 4)), origins_tips)\n",
    "\n",
    "    min_dist = []\n",
    "    min_dist.append(np.min(dist_mat_tips_origins, axis=1))\n",
    "    min_dist.append(np.min(dist_mat_origins_tips, axis=1))\n",
    "\n",
    "    origins_or_tips = np.argmin(min_dist, axis = 0)\n",
    "\n",
    "    abs_min_dist = np.array([min_dist[selected][i] for i, selected in enumerate(origins_or_tips)])\n",
    "\n",
    "    directions = [None] * len(edges_endpoints)\n",
    "\n",
    "    for index in np.where(abs_min_dist < dist_threshold)[0]:\n",
    "        directions[index] = origins_or_tips[index]\n",
    "\n",
    "    return directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f546f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conections(nodes_df, edges_endpoints, edges_directionalities, img, dist_threshold_percentage = 5):\n",
    "    \n",
    "    nodes_contours = []\n",
    "    nodes_ids = []\n",
    "    edge_id = 0\n",
    "    edges_id =[]\n",
    "    for i, row in nodes_df.iterrows():\n",
    "        \n",
    "        img_out = np.zeros_like(img, dtype=np.uint16)\n",
    "        \n",
    "        img_out[ row.top : row.bottom, row.left : row.right ] = 1\n",
    "        \n",
    "        contour, tree = cv2.findContours(cv2.convertScaleAbs(img_out), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        assert len(contour) == 1\n",
    "        \n",
    "        nodes_contours.append(contour[0])\n",
    "        nodes_ids.append(row.node_id)\n",
    "        \n",
    "    \n",
    "    \n",
    "    edges_endpoints = edges_endpoints.astype(np.uint16)\n",
    "\n",
    "    connections = []\n",
    "    destination_nodes = []\n",
    "    \n",
    "\n",
    "\n",
    "    dist_threshold_in_pixels = int((dist_threshold_percentage / 100) * img.shape[0])\n",
    "\n",
    "    for edge_i, edge in enumerate(edges_endpoints):\n",
    "\n",
    "        connection = [None, None]\n",
    "\n",
    "        for i_endpoint, endpoint in enumerate(edge):\n",
    "\n",
    "            min_dist_to_node = 9e3\n",
    "            min_dist_node_n = -1\n",
    "\n",
    "            for i_node, node in enumerate(nodes_contours):\n",
    "\n",
    "                min_dist = cv2.pointPolygonTest(node, endpoint, True) * (-1)\n",
    "\n",
    "\n",
    "                if min_dist < min_dist_to_node:\n",
    "                    min_dist_to_node = min_dist\n",
    "                    min_dist_node_n = nodes_ids[i_node]\n",
    "\n",
    "            if min_dist_to_node < dist_threshold_in_pixels:\n",
    "\n",
    "                connection[i_endpoint] = min_dist_node_n\n",
    "\n",
    "        if connection[0] is not None and connection[1] is not None and connection[0] != connection[1]:\n",
    "            connections.append(connection) \n",
    "            edges_id.append(edge_id)\n",
    "            if edges_directionalities[edge_i] is not None:\n",
    "                dest_node = connection[edges_directionalities[edge_i]]\n",
    "            else:\n",
    "                dest_node = None\n",
    "                \n",
    "            destination_nodes.append(dest_node)\n",
    "        edge_id = edge_id+1\n",
    "\n",
    "    df_pre = pd.DataFrame(connections, columns=['node a', 'node b'])\n",
    "    df_pre.insert(column='destination node', loc=2, value=destination_nodes)\n",
    "\n",
    "#     froze_set = set([frozenset([row['node a'], row['node b']]) for i, row in df_pre.iterrows()])\n",
    "\n",
    "#     df = pd.DataFrame(froze_set, columns=['node a', 'node b'])\n",
    "#     df['destination node'] = None\n",
    "    \n",
    "#     for i, row in df.iterrows():\n",
    "        \n",
    "#         dest_nodes = df_pre.loc[((df_pre['node a'] == row['node a']) & (df_pre['node b'] == row['node b']) |\n",
    "#                         (df_pre['node b'] == row['node a']) & (df_pre['node a'] == row['node b'])), 'destination node']\n",
    "        \n",
    "#         df.at[i, 'destination node'] = dest_nodes.max()\n",
    "#     print(edges_id)\n",
    "    \n",
    "    return df_pre,edges_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73793bbb-e2b6-4408-8240-31bc6d1418a5",
   "metadata": {},
   "source": [
    "## Load detectors (ViT) models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b48d3d3-4fb7-4fa9-89a3-07a6f4759bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drawing_checkpoint = \"peter9356/models\"\n",
    "# edge_tip_checkpoint = \"peter9356/models\"\n",
    "# node_checkpoint = \"peter9356/models\"\n",
    "drawing_checkpoint = \"models/drawing\"\n",
    "edge_tip_checkpoint = \"models/edge_tip\"\n",
    "node_checkpoint = \"models/node\"\n",
    "\n",
    "drawing_image_processor = AutoImageProcessor.from_pretrained(drawing_checkpoint)\n",
    "drawing_model = AutoModelForObjectDetection.from_pretrained(drawing_checkpoint)\n",
    "\n",
    "edge_tip_image_processor = AutoImageProcessor.from_pretrained(edge_tip_checkpoint)\n",
    "edge_tip_model = AutoModelForObjectDetection.from_pretrained(edge_tip_checkpoint)\n",
    "\n",
    "node_image_processor = AutoImageProcessor.from_pretrained(node_checkpoint)\n",
    "node_model = AutoModelForObjectDetection.from_pretrained(node_checkpoint)\n",
    "\n",
    "def get_drawings_predictions(image, threshold=0.1):\n",
    "\n",
    "    img     = Image.fromarray(image)\n",
    "    inputs  = drawing_image_processor(images=img, return_tensors=\"pt\")\n",
    "    outputs = drawing_model(**inputs)\n",
    "    \n",
    "    target_sizes = torch.tensor([img.size[::-1]])\n",
    "    return drawing_image_processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=threshold)[0]\n",
    "\n",
    "def get_edge_tip_predictions(image, threshold=0.1):\n",
    "\n",
    "    img     = Image.fromarray(image)\n",
    "    inputs  = edge_tip_image_processor(images=img, return_tensors=\"pt\")\n",
    "    outputs = edge_tip_model(**inputs)\n",
    "    \n",
    "    target_sizes = torch.tensor([img.size[::-1]])\n",
    "    return edge_tip_image_processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=threshold)[0]\n",
    "\n",
    "def get_node_predictions(image, threshold=0.1):\n",
    "\n",
    "    img     = Image.fromarray(image)\n",
    "    inputs  = node_image_processor(images=img, return_tensors=\"pt\")\n",
    "    outputs = node_model(**inputs)\n",
    "    \n",
    "    target_sizes = torch.tensor([img.size[::-1]])\n",
    "    return node_image_processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=threshold)[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b8c707a-929b-4c51-87a1-c107e18b31ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.yolos.image_processing_yolos.YolosImageProcessor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(drawing_image_processor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92caaae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edges_endpoints_directionality_vit(edges_endpoints, image, edges_directionalities, score_threshold):    \n",
    "    \n",
    "    edge_tips_vit = get_edge_tip_predictions(image)\n",
    "    \n",
    "    tolerance_margin_pixels = 5\n",
    "    min_score               = 0.3\n",
    "    min_difference_score    = 0.1\n",
    "\n",
    "    edges_directionalities_vit = []\n",
    "    vit_scores                 = []\n",
    "\n",
    "    for i, edge_endpoint in enumerate(edges_endpoints):\n",
    "\n",
    "        x_0 = edge_endpoint[0][0]\n",
    "        y_0 = edge_endpoint[0][1]\n",
    "\n",
    "        x_1 = edge_endpoint[1][0]\n",
    "        y_1 = edge_endpoint[1][1]\n",
    "\n",
    "        scores_0 = [0]\n",
    "        scores_1 = [0]\n",
    "\n",
    "        for j, edge_tip_vit in enumerate(edge_tips_vit['boxes']):\n",
    "\n",
    "            bb_x0 = edge_tip_vit[0] - tolerance_margin_pixels\n",
    "            bb_x1 = edge_tip_vit[2] + tolerance_margin_pixels\n",
    "\n",
    "            bb_y0 = edge_tip_vit[1] - tolerance_margin_pixels\n",
    "            bb_y1 = edge_tip_vit[3] + tolerance_margin_pixels\n",
    "\n",
    "\n",
    "            if (x_0 >= bb_x0 and x_0 <= bb_x1 and\n",
    "                y_0 >= bb_y0 and y_0 <= bb_y1):\n",
    "\n",
    "                scores_0.append(round(float(edge_tips_vit['scores'][j]), 2))\n",
    "\n",
    "\n",
    "            if (x_1 >= bb_x0 and x_1 <= bb_x1 and\n",
    "                y_1 >= bb_y0 and y_1 <= bb_y1):\n",
    "\n",
    "                scores_1.append(round(float(edge_tips_vit['scores'][j]), 2))\n",
    "\n",
    "        max_score_0 = np.max(scores_0)\n",
    "        max_score_1 = np.max(scores_1)\n",
    "\n",
    "        if max_score_0 > min_score and max_score_0 > max_score_1 + min_difference_score:\n",
    "            edges_directionalities_vit.append(0)\n",
    "            vit_scores.append(max_score_0)\n",
    "\n",
    "        elif max_score_1 > min_score and max_score_1 > max_score_0 + min_difference_score:\n",
    "            edges_directionalities_vit.append(1)\n",
    "            vit_scores.append(max_score_1)\n",
    "\n",
    "        else:\n",
    "            edges_directionalities_vit.append(None)\n",
    "            vit_scores.append(0)\n",
    "    \n",
    "    \n",
    "    #compare vit and opencv approaches\n",
    "    \n",
    "    final_edges_directionalities = []\n",
    "    \n",
    "    for i in range(len(edges_directionalities)):\n",
    "    \n",
    "    \n",
    "        if edges_directionalities[i] == edges_directionalities_vit[i]:\n",
    "            \n",
    "            final_edges_directionalities.append(edges_directionalities[i])\n",
    "            \n",
    "            \n",
    "            \n",
    "        elif edges_directionalities[i] == None and vit_scores[i] > score_threshold: \n",
    "            \n",
    "            final_edges_directionalities.append(edges_directionalities_vit[i])\n",
    "            \n",
    "            \n",
    "            \n",
    "        elif edges_directionalities_vit[i] == None:\n",
    "            \n",
    "            final_edges_directionalities.append(edges_directionalities[i])\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            \n",
    "            if vit_scores[i] > score_threshold:\n",
    "                final_edges_directionalities.append(edges_directionalities_vit[i])\n",
    "            else:\n",
    "                final_edges_directionalities.append(edges_directionalities[i])\n",
    "    \n",
    "    return final_edges_directionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48fc368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repeated_connections(df):\n",
    "    \n",
    "    to_remove = []\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        \n",
    "        repeated_rows = df[(((df['node a'] == row['node a']) & (df['node b'] == row['node b'])) |\n",
    "                          ((  df['node a'] == row['node b']) & (df['node b'] == row['node a'])))]\n",
    "        \n",
    "        \n",
    "        if len(repeated_rows) > 1:\n",
    "            \n",
    "            flag_done = False\n",
    "            \n",
    "            for j, row2 in repeated_rows.iterrows():\n",
    "            \n",
    "                if np.isnan(row2['destination node']) == False:\n",
    "                    \n",
    "                    to_remove.extend(repeated_rows.index)\n",
    "                    to_remove.remove(j)\n",
    "                    flag_done = True\n",
    "                    break\n",
    "            \n",
    "            if flag_done == False:\n",
    "                to_remove.extend(repeated_rows.index[1:])\n",
    "    \n",
    "    \n",
    "    df.drop(index=list(set(to_remove)), inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65e798df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104024FC-16A3-4D4B-8EEA-75055D623129-1661588297.695\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(example_folder)\n\u001b[1;32m---> 14\u001b[0m image_file_name \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_folder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendswith\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendswith\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     18\u001b[0m ocr \u001b[38;5;241m=\u001b[39m get_ocr_data(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(main_folder, example_folder, example_folder, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manalyzeDocResponse.json\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     20\u001b[0m image \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "all_nodes_df = []\n",
    "all_connections_df = []\n",
    "all_images = []\n",
    "\n",
    "for index in range(len(ann_examples)):\n",
    "\n",
    "    example_folder = ann_examples[index]\n",
    "    \n",
    "    if example_folder in to_exclude_to_time_complexity:\n",
    "        continue\n",
    "    \n",
    "    print(example_folder)\n",
    "    \n",
    "    image_file_name = [f for f in os.listdir(os.path.join(main_folder, example_folder)) \n",
    "                        if f.lower().endswith('png') or f.lower().endswith('jpg')][0]\n",
    "    \n",
    "    \n",
    "    ocr = get_ocr_data(os.path.join(main_folder, example_folder, example_folder, 'analyzeDocResponse.json'))\n",
    "\n",
    "    image = []\n",
    "    \n",
    "    image_file_name = [f for f in os.listdir(os.path.join(main_folder, example_folder)) \n",
    "                        if f.lower().endswith('png') or f.lower().endswith('jpg')][0]\n",
    "    \n",
    "    image.append(open_image(os.path.join(main_folder, example_folder,image_file_name)))\n",
    "    \n",
    "    \n",
    "    ocr = set_bounding_boxes_in_pixels(ocr, image[-1])\n",
    "    ocr = get_font_size(ocr)\n",
    "    ocr = join_close_nodes(ocr, vertical_distance_threshold_percent=25, horizontal_distance_threshold_percent=50)\n",
    "  \n",
    "    image_no_thresholding = cv2.convertScaleAbs(substract_bounding_boxes(ocr, image[0], 20))\n",
    "    arrow_origins, arrow_tips, arrow_length,arrow_thickness = detect_arrows(image_no_thresholding, dilate_max=5, erode_max=5, rounding_max = 0.05, rounding_step=0.002)\n",
    "    \n",
    "    image.append(threshold_image(image[-1]))\n",
    "    image.append(stamp_bounding_boxes_on_image(ocr, image[-1], erotion_percent = 10))\n",
    "    #image.append(close_shape_gaps5(image[-1], ocr, dist_threshold_percent = 30))\n",
    "    \n",
    "    image.append(get_filled_shapes(image[-1]))\n",
    "    \n",
    "    nodes_mask, edges_mask = get_masks(image[-1], max_iter=5)\n",
    "    \n",
    "    image.append(nodes_mask)\n",
    "    image.append(edges_mask)\n",
    "    \n",
    "    edges_endpoints, edges_endpoints_features = get_edges_endpoints(edges_mask, min_edge_length_percentage=1.5)\n",
    "    \n",
    "    edges_directionalities = get_edges_endpoints_directionality(edges_endpoints, arrow_tips, arrow_origins, dist_threshold=50)\n",
    "    \n",
    "    \n",
    "    #uses vit to predict edge_tip and compares both opencv and vit approaches using a simple logic\n",
    "    final_edges_directionalities = get_edges_endpoints_directionality_vit(edges_endpoints, image[0], \n",
    "                                                                          edges_directionalities, score_threshold=0.3)\n",
    "    \n",
    "    \n",
    "    nodes_df = get_nodes(ocr, nodes_mask, threshold_iou = 0.3)\n",
    "    \n",
    "    nodes_df['text'] = nodes_df.text.apply(spellcheck2)\n",
    "\n",
    "    connections_df,edges_id = get_conections(nodes_df, edges_endpoints, final_edges_directionalities, \n",
    "                                    image[-1], dist_threshold_percentage = 20)\n",
    "    \n",
    "    \n",
    "    final_edges_feature = edges_endpoints_features[edges_id]\n",
    "    df_edge_features = pd.DataFrame(final_edges_feature, columns=['id', 'length', 'thickness'])\n",
    "    \n",
    "    connections_df = pd.concat([connections_df, df_edge_features], axis=1)\n",
    "    \n",
    "    connections_df = remove_repeated_connections(connections_df)\n",
    "\n",
    "    \n",
    "    all_nodes_df.append(nodes_df)\n",
    "    all_connections_df.append(connections_df)\n",
    "    all_images.append(image[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e22493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_f1 = []\n",
    "nodes_pr = []\n",
    "nodes_re = []\n",
    "\n",
    "edges_f1 = []\n",
    "edges_pr = []\n",
    "edges_re = []\n",
    "\n",
    "directions_f1 = []\n",
    "directions_pr = []\n",
    "directions_re = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for index in range(len(ann_examples)):\n",
    "\n",
    "    example_folder = ann_examples[index]\n",
    "    \n",
    "    if example_folder in to_exclude_to_time_complexity:\n",
    "        continue\n",
    "    \n",
    "    print(example_folder)\n",
    "\n",
    "    ann_edges = pd.read_excel(os.path.join(main_folder, example_folder, 'annotated edges.xlsx'))\n",
    "    \n",
    "    ann_nodes = pd.read_excel(os.path.join(main_folder, example_folder, 'annotated nodes.xlsx'))\n",
    "    ann_nodes = filter_image_nodes_from_annotated_df(ann_nodes)\n",
    "    \n",
    "    f1, pr, re = get_nodes_metrics(ann_nodes, all_nodes_df[counter])\n",
    "    \n",
    "    nodes_f1.append(f1)\n",
    "    nodes_pr.append(pr)\n",
    "    nodes_re.append(re)\n",
    "    \n",
    "    f1, pr, re = get_edges_metrics(ann_nodes, all_nodes_df[counter], ann_edges, all_connections_df[counter])\n",
    "    \n",
    "    edges_f1.append(f1)\n",
    "    edges_pr.append(pr)\n",
    "    edges_re.append(re)\n",
    "    \n",
    "    f1, pr, re = get_direction_metrics(ann_nodes, all_nodes_df[counter], ann_edges, all_connections_df[counter])\n",
    "    \n",
    "    directions_f1.append(f1)\n",
    "    directions_pr.append(pr)\n",
    "    directions_re.append(re)\n",
    "    \n",
    "    counter += 1\n",
    "    \n",
    "show_results(nodes_f1, nodes_pr, nodes_re, \n",
    "             edges_f1, edges_pr, edges_re,\n",
    "             directions_f1, directions_pr, directions_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed8d5ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075c7011-5713-4d7e-a7f7-21ece4f58d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448b1696-4fe3-4f6c-b0d3-a20034548a77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
